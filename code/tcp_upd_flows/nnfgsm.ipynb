{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/as9820/home/anaconda3/envs/test1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/rds/general/user/as9820/home/anaconda3/envs/test1/lib/python3.9/site-packages/art/estimators/certification/__init__.py:28: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, LSTM, Bidirectional\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "import sys, os, time, json, datetime, glob\n",
    "\n",
    "from logzero import logger\n",
    "import warnings\n",
    "#import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "\n",
    "from art.metrics import RobustnessVerificationTreeModelsCliqueMethod\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod, SaliencyMapMethod\n",
    "from art.estimators.classification import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = 19, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(41, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.8254068.pbs/ipykernel_3720150/4075129579.py:1: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/rds/general/user/as9820/home/revist/revisiting-iot-device-identification/data/features_nov-apr.csv\", parse_dates = ['time_start'])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/rds/general/user/as9820/home/revist/revisiting-iot-device-identification/data/features_nov-apr.csv\", parse_dates = ['time_start'])\n",
    "df.fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "packets = [] \n",
    "i = 0\n",
    "    \n",
    "devs = ['appkettle','blink-security-hub','bosiwo-camera-wifi','lefun-cam-wired','insteon-hub',\n",
    "            'echoplus','meross-dooropener','smartlife-bulb','xiaomi-ricecooker','ubell-doorbell',\n",
    "            'appletv','tplink-bulb','google-home','icsee-doorbell','t-wemo-plug','echospot',\n",
    "            'nest-tstat','sousvide','smartlife-remote','netatmo-weather-station','lgtv-wifi',\n",
    "            'wansview-cam-wired','xiaomi-plug','xiaomi-hub','lightify-hub','bosiwo-camera-wired',\n",
    "            'tplink-plug2','allure-speaker','honeywell-thermostat','smarter-coffee-mach','roku-tv',\n",
    "            'yi-camera','firetv','echodot','smartthings-hub','reolink-cam-wired','t-philips-hub',\n",
    "            'switchbot-hub','ring-doorbell','blink-camera','samsungtv-wired']\n",
    "\n",
    "features = ['srcPort', 'destPort',\n",
    "       'bytes_out', 'num_pkts_out', 'bytes_in', 'num_pkts_in', 'f_ipt_mean',\n",
    "       'f_ipt_std', 'f_ipt_var', 'f_ipt_skew', 'f_ipt_kurtosis', 'f_b_mean',\n",
    "       'f_b_std', 'f_b_var', 'f_b_skew', 'f_b_kurtosis', 'duration', 'pr',\n",
    "       'domainId']\n",
    "label = 'deviceId'\n",
    "\n",
    "#weeksToProcess = list(range(44,53)) + list(range(1,19))\n",
    "weeks = [list(range(44,53)), list(range(1,10)), list(range(10,19))]\n",
    "weeksToProcess = weeks[0] + weeks[1] + weeks[2]\n",
    "#weeksToProcess = weeks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCon = df['time_start'].dt.isocalendar().week.isin(weeks[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCons = pd.date_range('2019-11-01', '2020-05-01', freq = '1Y').tolist()\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(range(1,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 10:55:48.710068: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-09-19 10:55:48.710520: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-19 10:55:48.731164: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 32. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-19 10:55:48.740536: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2023-09-19 10:55:48.753918: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249970000 Hz\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"model.15-0.43.h5\", compile=False)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "classifier = KerasClassifier(model=model, clip_values=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting scalar\n",
      "labelled scalar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "JSMA: 100%|██████████| 4800/4800 [06:20<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fgsm generated\n",
      "Accuracy on adversarial test data: 7.90%\n",
      "Average perturbation: 0.78\n",
      "7.910303745070824\n"
     ]
    }
   ],
   "source": [
    "\n",
    "attack_fgsm = SaliencyMapMethod(classifier=classifier, batch_size=1)\n",
    "for date in testCons:\n",
    "    testCon = df['time_start'].dt.isocalendar().week == pd.Timestamp(date).week\n",
    "    #testCon = df['time'].dt.date == pd.Timestamp(date).date\n",
    "    #testDF = df[testCon]\n",
    "    testDF = df\n",
    "\n",
    "    X = testDF[features]\n",
    "    y = testDF[label]\n",
    "\n",
    "    if len(X) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(\"starting scalar\")\n",
    "\n",
    "    scaler = StandardScaler().fit(df[trainCon][features].values)\n",
    "    X = scaler.transform(X.values)\n",
    "    \n",
    "    \n",
    "            \n",
    "    labels = lb.transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=4800, stratify=y)\n",
    " \n",
    "    print(\"labelled scalar\") \n",
    "    labels = lb.transform(y_test)\n",
    "    \n",
    "    x_test_adv = attack_fgsm.generate(X_test)\n",
    "    np.savetxt(f\"nnjsma-{date.week}.csv\", x_test_adv, delimiter=\",\")\n",
    "    print(\"fgsm generated\")\n",
    "    loss_test, accuracy_test = model.evaluate(x_test_adv, y_test-1)\n",
    "    perturbation = np.mean(np.abs((x_test_adv - X_test)))\n",
    "    print('Accuracy on adversarial test data: {:4.2f}%'.format(accuracy_test * 100))\n",
    "    print('Average perturbation: {:4.2f}'.format(perturbation))\n",
    "    for index, sample in enumerate (x_test_adv):\n",
    "        dist = dist + np.linalg.norm(sample-X_test[index])\n",
    "    print(dist/4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.059913425003889\n"
     ]
    }
   ],
   "source": [
    "dist=0\n",
    "for index, sample in enumerate (x_test_adv):\n",
    "    dist = dist + np.linalg.norm(sample-X_test[index])\n",
    "print(dist/4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial test data: 7.12%\n"
     ]
    }
   ],
   "source": [
    "#y_test = np_utils.to_categorical(y_test, 41)\n",
    "y_test = y_test-1\n",
    "loss_test, accuracy_test = model.evaluate(x_test_adv, y_test)\n",
    "perturbation = np.mean(np.abs((x_test_adv - X_test)))\n",
    "print('Accuracy on adversarial test data: {:4.2f}%'.format(accuracy_test * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KerasClassifier' object has no attribute 'get_trees'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n\u001b[1;32m      2\u001b[0m X_test \u001b[38;5;241m=\u001b[39m normalize(X\u001b[38;5;241m=\u001b[39mX_test)\n\u001b[0;32m----> 4\u001b[0m rt \u001b[38;5;241m=\u001b[39m \u001b[43mRobustnessVerificationTreeModelsCliqueMethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m average_bound, verified_error \u001b[38;5;241m=\u001b[39m rt\u001b[38;5;241m.\u001b[39mverify(x\u001b[38;5;241m=\u001b[39mX_test, y\u001b[38;5;241m=\u001b[39my_test, eps_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, nb_search_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, max_clique\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m      6\u001b[0m                                           max_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage bound:\u001b[39m\u001b[38;5;124m'\u001b[39m, average_bound)\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.9/site-packages/art/metrics/verification_decisions_trees.py:181\u001b[0m, in \u001b[0;36mRobustnessVerificationTreeModelsCliqueMethod.__init__\u001b[0;34m(self, classifier, verbose)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_classifier \u001b[38;5;241m=\u001b[39m classifier\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trees \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_trees\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'get_trees'"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=200, stratify=y)\n",
    "X_test = normalize(X=X_test)\n",
    "\n",
    "rt = RobustnessVerificationTreeModelsCliqueMethod(classifier=classifier)\n",
    "average_bound, verified_error = rt.verify(x=X_test, y=y_test, eps_init=0.3, nb_search_steps=10, max_clique=2, \n",
    "                                          max_level=2)\n",
    "\n",
    "print('Average bound:', average_bound)\n",
    "print('Verified error at eps:', verified_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      2\u001b[0m indexes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mrange\u001b[39m(num_samples))\n\u001b[0;32m----> 3\u001b[0m extra_model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m()\n\u001b[1;32m      5\u001b[0m extra_classifier \u001b[38;5;241m=\u001b[39m ScikitlearnRandomForestClassifier(extra_model)\n\u001b[1;32m      6\u001b[0m leakage, _, _ \u001b[38;5;241m=\u001b[39m PDTP(art_classifier, extra_classifier, x_train, y_train, indexes\u001b[38;5;241m=\u001b[39mindexes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "num_samples=100\n",
    "indexes = np.array(range(num_samples))\n",
    "extra_model = RandomForestClassifier()\n",
    "\n",
    "extra_classifier = ScikitlearnRandomForestClassifier(extra_model)\n",
    "leakage, _, _ = PDTP(art_classifier, extra_classifier, x_train, y_train, indexes=indexes)\n",
    "\n",
    "print(\"Average PDTP leakage random forest: \", np.average(leakage))\n",
    "print(\"Max PDTP leakage random forest: \", np.max(leakage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9 (test1)",
   "language": "python",
   "name": "python39_test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
