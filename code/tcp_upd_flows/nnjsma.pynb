{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/as9820/home/anaconda3/envs/test1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/rds/general/user/as9820/home/anaconda3/envs/test1/lib/python3.9/site-packages/art/estimators/certification/__init__.py:28: UserWarning: PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ or Interval Bound Propagation functionality\")\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, Conv1D, MaxPooling2D, MaxPooling1D, LSTM, Bidirectional\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys, os, time, json, datetime, glob\n",
    "\n",
    "from logzero import logger\n",
    "import warnings\n",
    "#import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "\n",
    "from art.attacks.evasion import FastGradientMethod\n",
    "from art.estimators.classification import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = 19, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(41, activation='softmax'))\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.8250957.pbs/ipykernel_3251527/4075129579.py:1: DtypeWarning: Columns (22,23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"/rds/general/user/as9820/home/revist/revisiting-iot-device-identification/data/features_nov-apr.csv\", parse_dates = ['time_start'])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/rds/general/user/as9820/home/revist/revisiting-iot-device-identification/data/features_nov-apr.csv\", parse_dates = ['time_start'])\n",
    "df.fillna(0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "packets = [] \n",
    "i = 0\n",
    "    \n",
    "devs = ['appkettle','blink-security-hub','bosiwo-camera-wifi','lefun-cam-wired','insteon-hub',\n",
    "            'echoplus','meross-dooropener','smartlife-bulb','xiaomi-ricecooker','ubell-doorbell',\n",
    "            'appletv','tplink-bulb','google-home','icsee-doorbell','t-wemo-plug','echospot',\n",
    "            'nest-tstat','sousvide','smartlife-remote','netatmo-weather-station','lgtv-wifi',\n",
    "            'wansview-cam-wired','xiaomi-plug','xiaomi-hub','lightify-hub','bosiwo-camera-wired',\n",
    "            'tplink-plug2','allure-speaker','honeywell-thermostat','smarter-coffee-mach','roku-tv',\n",
    "            'yi-camera','firetv','echodot','smartthings-hub','reolink-cam-wired','t-philips-hub',\n",
    "            'switchbot-hub','ring-doorbell','blink-camera','samsungtv-wired']\n",
    "\n",
    "features = ['srcPort', 'destPort',\n",
    "       'bytes_out', 'num_pkts_out', 'bytes_in', 'num_pkts_in', 'f_ipt_mean',\n",
    "       'f_ipt_std', 'f_ipt_var', 'f_ipt_skew', 'f_ipt_kurtosis', 'f_b_mean',\n",
    "       'f_b_std', 'f_b_var', 'f_b_skew', 'f_b_kurtosis', 'duration', 'pr',\n",
    "       'domainId']\n",
    "label = 'deviceId'\n",
    "\n",
    "#weeksToProcess = list(range(44,53)) + list(range(1,19))\n",
    "weeks = [list(range(44,53)), list(range(1,10)), list(range(10,19))]\n",
    "weeksToProcess = weeks[0] + weeks[1] + weeks[2]\n",
    "#weeksToProcess = weeks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainCon = df['time_start'].dt.isocalendar().week.isin(weeks[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testCons = pd.date_range('2019-11-01', '2020-05-01', freq = '1Y').tolist()\n",
    "lb = LabelBinarizer()\n",
    "lb.fit(range(1,42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 16:30:23.483985: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-09-18 16:30:23.484263: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 16:30:23.503804: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 32. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-09-18 16:30:23.512888: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "2023-09-18 16:30:23.526875: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2249970000 Hz\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"model.15-0.43.h5\", compile=False)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "classifier = KerasClassifier(model=model, clip_values=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting scalar\n",
      "labelled scalar\n",
      "fgsm generated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 16:35:06.130301: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at sparse_xent_op.cc:90 : Invalid argument: Received a label value of 41 which is outside the valid range of [0, 41).  Label values: 3 13 28 13 13 37 7 13 32 34 34 13 6 13 16 17 10 28 13 13 22 10 41 41 22 35 19 15 28 16 41 38\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of 41 which is outside the valid range of [0, 41).  Label values: 3 13 28 13 13 37 7 13 32 34 34 13 6 13 16 17 10 28 13 13 22 10 41 41 22 35 19 15 28 16 41 38\n\t [[{{node loss_1/dense_3_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnnfgsm-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate\u001b[38;5;241m.\u001b[39mweek\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, x_test_adv, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfgsm generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m loss_test, accuracy_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test_adv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m perturbation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(np\u001b[38;5;241m.\u001b[39mabs((x_test_adv \u001b[38;5;241m-\u001b[39m X_test)))\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy on adversarial test data: \u001b[39m\u001b[38;5;132;01m{:4.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(accuracy_test \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_v1.py:903\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    902\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 903\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    904\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    910\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:685\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.evaluate\u001b[0;34m(self, model, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    676\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps, x)\n\u001b[1;32m    677\u001b[0m x, y, sample_weights \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_standardize_user_data(\n\u001b[1;32m    678\u001b[0m     x,\n\u001b[1;32m    679\u001b[0m     y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    683\u001b[0m     steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    684\u001b[0m     steps\u001b[38;5;241m=\u001b[39msteps)\n\u001b[0;32m--> 685\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtest_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.9/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:384\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(mode, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m'\u001b[39m, batch_index, batch_logs)\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[0;32m--> 384\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    386\u001b[0m   batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.9/site-packages/tensorflow/python/keras/backend.py:3956\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3950\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   3951\u001b[0m     symbol_vals \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol_vals \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   3952\u001b[0m     feed_symbols \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_symbols \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetches \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   3953\u001b[0m     session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session):\n\u001b[1;32m   3954\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 3956\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_callable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marray_vals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3957\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3958\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches):])\n\u001b[1;32m   3959\u001b[0m output_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   3960\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_structure,\n\u001b[1;32m   3961\u001b[0m     fetched[:\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs)],\n\u001b[1;32m   3962\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/test1/lib/python3.9/site-packages/tensorflow/python/client/session.py:1480\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1479\u001b[0m   run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1480\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRunCallable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m                                         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1483\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1484\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 41 which is outside the valid range of [0, 41).  Label values: 3 13 28 13 13 37 7 13 32 34 34 13 6 13 16 17 10 28 13 13 22 10 41 41 22 35 19 15 28 16 41 38\n\t [[{{node loss_1/dense_3_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]"
     ]
    }
   ],
   "source": [
    "\n",
    "attack_fgsm = FastGradientMethod(estimator=classifier, eps=0.3)\n",
    "for date in testCons:\n",
    "    testCon = df['time_start'].dt.isocalendar().week == pd.Timestamp(date).week\n",
    "    #testCon = df['time'].dt.date == pd.Timestamp(date).date\n",
    "    #testDF = df[testCon]\n",
    "    testDF = df\n",
    "\n",
    "    X = testDF[features]\n",
    "    y = testDF[label]\n",
    "\n",
    "    if len(X) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(\"starting scalar\")\n",
    "\n",
    "    scaler = StandardScaler().fit(df[trainCon][features].values)\n",
    "    X = scaler.transform(X.values)\n",
    "    \n",
    "    \n",
    "            \n",
    "    labels = lb.transform(y)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=800, stratify=y)\n",
    " \n",
    "    print(\"labelled scalar\") \n",
    "    labels = lb.transform(y_test)\n",
    "    \n",
    "    x_test_adv = attack_fgsm.generate(X_test)\n",
    "    np.savetxt(f\"nnfgsm-{date.week}.csv\", x_test_adv, delimiter=\",\")\n",
    "    print(\"fgsm generated\")\n",
    "    #loss_test, accuracy_test = model.evaluate(x_test_adv, y_test)\n",
    "    perturbation = np.mean(np.abs((x_test_adv - X_test)))\n",
    "    #print('Accuracy on adversarial test data: {:4.2f}%'.format(accuracy_test * 100))\n",
    "    print('Average perturbation: {:4.2f}'.format(perturbation))\n",
    "    dist = np.linalg.norm(x_test_adv-X_test)\n",
    "    print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.9 (test1)",
   "language": "python",
   "name": "python39_test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
